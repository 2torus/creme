{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:1219: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.82570096332665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.mean_squared_error)\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "model = compose.Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('learn', linear_model.SGDRegressor(\n",
    "        fit_intercept=True,\n",
    "        max_iter=1,\n",
    "        tol=1e-3\n",
    "    ))\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101.9066103061728"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import creme.linear_model\n",
    "import creme.pipeline\n",
    "import creme.preprocessing.\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.mean_squared_error)\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "model = creme.compose.Pipeline([\n",
    "    ('scale', creme.preprocessing..StandardScaler()),\n",
    "    ('learn', creme.linear_model.LinearRegression(\n",
    "        creme.linear_model.optimize.VanillaSGD(\n",
    "            lr=creme.linear_model.optimize.ConstantLR(0.01),\n",
    "            l2=0.01\n",
    "        ),\n",
    "    ))\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regressor'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._final_estimator._estimator_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38507.74943484116"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import creme.model_selection\n",
    "import creme.stream\n",
    "\n",
    "s = creme.stream.iter_sklearn_dataset(datasets.load_boston())\n",
    "creme.model_selection.online_score(s, model, metrics.mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9455808252682341"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "model = compose.Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('learn', linear_model.SGDClassifier(max_iter=1, tol=1e-3, random_state=42))\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713154495816967"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import creme.linear_model\n",
    "import creme.pipeline\n",
    "import creme.preprocessing.\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "model = creme.compose.Pipeline([\n",
    "    ('scale', creme.preprocessing..StandardScaler()),\n",
    "    ('learn', creme.linear_model.LogisticRegression(batch_size=1))\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/max/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7733333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import multiclass\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "model = compose.Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('learn', multiclass.OneVsRestClassifier(\n",
    "        linear_model.SGDClassifier(max_iter=1, tol=1e-3, random_state=42)\n",
    "    ))\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import creme.linear_model\n",
    "import creme.multiclass\n",
    "import creme.pipeline\n",
    "import creme.preprocessing.\n",
    "\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "optimizer = creme.linear_model.optimize.AdaGrad(lr=0.4)\n",
    "model = creme.compose.Pipeline([\n",
    "    ('scale', creme.preprocessing..StandardScaler()),\n",
    "    ('learn', creme.multiclass.OneVsRestClassifier(\n",
    "        base_estimator=creme.linear_model.LogisticRegression(optimizer))\n",
    "    )\n",
    "])\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': 0.0453409833354632,\n",
       "  'sex': -0.044641636506989,\n",
       "  'bmi': -0.00620595413580824,\n",
       "  'bp': -0.015999222636143,\n",
       "  's1': 0.125018703134293,\n",
       "  's2': 0.125198101136752,\n",
       "  's3': 0.0191869970174533,\n",
       "  's4': 0.0343088588777263,\n",
       "  's5': 0.0324332257796019,\n",
       "  's6': -0.0052198044153011},\n",
       " 219.0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y = creme.stream.iter_sklearn_dataset(\n",
    "    dataset=datasets.load_diabetes(),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "list(X_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "params = {\n",
    "    'categories': [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ],\n",
    "    'remove': ('headers', 'footers', 'quotes'),\n",
    "    'shuffle': True,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "train = datasets.fetch_20newsgroups(subset='train', **params)\n",
    "test = datasets.fetch_20newsgroups(subset='test', **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.56      0.71      0.63       319\n",
      "     comp.graphics       0.90      0.88      0.89       389\n",
      "         sci.space       0.68      0.93      0.78       394\n",
      "talk.religion.misc       0.78      0.07      0.13       251\n",
      "\n",
      "         micro avg       0.71      0.71      0.71      1353\n",
      "         macro avg       0.73      0.65      0.61      1353\n",
      "      weighted avg       0.73      0.71      0.66      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import creme.feature_extraction\n",
    "import creme.naive_bayes\n",
    "import creme.pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "model = creme.compose.Pipeline([\n",
    "    ('vectorize', creme.feature_extraction.TFIDFVectorizer(on='text')),\n",
    "    ('naive_bayes', creme.naive_bayes.MultinomialNB())\n",
    "])\n",
    "\n",
    "for x, y in zip(train['data'], train['target']):\n",
    "    model.fit_one({'text': x}, train['target_names'][y])\n",
    "    \n",
    "y_true = [None] * len(test['data'])\n",
    "y_pred = [None] * len(test['data'])\n",
    "\n",
    "for i, (x, y) in enumerate(zip(test['data'], test['target'])):\n",
    "    y_true[i] = test['target_names'][y]\n",
    "    y_pred[i] = model.predict_one({'text': x})\n",
    "    \n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.55      0.75      0.63       319\n",
      "     comp.graphics       0.90      0.88      0.89       389\n",
      "         sci.space       0.70      0.92      0.80       394\n",
      "talk.religion.misc       0.78      0.07      0.13       251\n",
      "\n",
      "         micro avg       0.71      0.71      0.71      1353\n",
      "         macro avg       0.73      0.66      0.61      1353\n",
      "      weighted avg       0.74      0.71      0.66      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import pipeline\n",
    "\n",
    "\n",
    "skl_model = compose.Pipeline([\n",
    "    ('vectorize', feature_extraction.text.TfidfVectorizer()),\n",
    "    ('naive_bayes', naive_bayes.MultinomialNB())\n",
    "])\n",
    "\n",
    "X_train = train['data']\n",
    "y_train = list(map(lambda i: train['target_names'][i], train['target']))\n",
    "\n",
    "skl_model.fit(X_train, y_train);\n",
    "\n",
    "X_test = test['data']\n",
    "y_test = list(map(lambda i: test['target_names'][i], test['target']))\n",
    "y_pred = skl_model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
