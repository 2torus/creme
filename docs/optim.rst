Optimization
------------

.. automodule:: creme.optim
   :no-members:
   :no-inherited-members:

.. currentmodule:: creme.optim

Optimizers
++++++++++

.. autosummary::
   :toctree: generated/
   :nosignatures:

   AdaDelta
   AdaGrad
   Adam
   FTRLProximal
   Momentum
   NesterovMomentum
   Optimizer
   PassiveAggressiveI
   PassiveAggressiveII
   RMSProp
   VanillaSGD


Learning rate schedulers
++++++++++++++++++++++++

.. autosummary::
   :toctree: generated/
   :nosignatures:

   ConstantLR
   InverseScalingLR
   OptimalLR


Loss functions
++++++++++++++

.. autosummary::
   :toctree: generated/
   :nosignatures:

   AbsoluteLoss
   CauchyLoss
   EpsilonInsensitiveHingeLoss
   HingeLoss
   LogLoss
   Loss
   SquaredLoss
